{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Necessary imports "
      ],
      "metadata": {
        "id": "wNVbVP7LrKFA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZZD4FqrtBkf",
        "outputId": "a033cf44-b758-4932-9785-84ca1e251ad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:  999\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ff001480970>"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "import csv\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "manualSeed = 999\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "\n",
        "\n",
        "torch.manual_seed(manualSeed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Select appropriate device (CUDA or CPU) as per availability"
      ],
      "metadata": {
        "id": "AP9wsigGrUVD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqohFqnTsPnW"
      },
      "outputs": [],
      "source": [
        "use_cuda = True\n",
        "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###To load data, google drive is mounted."
      ],
      "metadata": {
        "id": "eTQR3pG5rbn-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22u16ZN0_seX",
        "outputId": "334a0a74-3bdc-4840-9c8d-103d1293bd4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The path for the train and test data is given.\n",
        "####Please change accordingly."
      ],
      "metadata": {
        "id": "4DDeDtyrsAg-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrF_2u1C0vDt"
      },
      "outputs": [],
      "source": [
        "train_dir = \"/content/gdrive/MyDrive/Colab Notebooks/data/train/train\"\n",
        "test_dir = \"/content/gdrive/MyDrive/Colab Notebooks/data/test\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####The class labels are extracted depending of each subfolder name inside the train folder"
      ],
      "metadata": {
        "id": "zP4aYqYRsn71"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_lFsM1EmlVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b756a624-b5f0-4026-d387-0dba071a23ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Cancer', 'Connective', 'Immune', 'Normal']"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ],
      "source": [
        "import pathlib\n",
        "classes = sorted([j.name.split('/')[-1] for j in pathlib.Path(train_dir).iterdir()])\n",
        "classes = classes[1:]\n",
        "classes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Spatial size of training images. All images will be resized to this size using a transformer. Our 32x32 image will be resized to 128x128. This magnifies the image to and give more details."
      ],
      "metadata": {
        "id": "fNfL85rgs_ST"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XBX5GhJ2NBz"
      },
      "outputs": [],
      "source": [
        "image_size = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###While transforming the data we want to normalize it. This is done by first calculating the mean and standard deviation of the dataset. \n",
        "####The dataset is loaded in batches of 128 images at a time."
      ],
      "metadata": {
        "id": "Q-AOjQMX1JW8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZt-eZMf77tw"
      },
      "outputs": [],
      "source": [
        "#train_dataset = dset.ImageFolder(root=train_dir,\n",
        "#                           transform=transforms.Compose([\n",
        "#                               transforms.Resize(image_size),\n",
        "#                               transforms.ToTensor(),\n",
        "#                           ]))\n",
        "#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 128, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siDq7S9U81RT"
      },
      "outputs": [],
      "source": [
        "def mean_and_std(loader):\n",
        "  mean =0.0\n",
        "  std =0.0\n",
        "  total_img_count =0\n",
        "  for images, _ in loader:\n",
        "    image_count_batch = images.size(0)\n",
        "    images = images.view(image_count_batch, images.size(1), -1)\n",
        "    mean += images.mean(2).sum(0)\n",
        "    std += images.std(2).sum(0)\n",
        "    total_img_count += image_count_batch\n",
        "  \n",
        "  mean /= total_img_count\n",
        "  std /= total_img_count\n",
        "\n",
        "  return mean, std\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###When dataset is passed to function mean_and_std(), the following is output mean and standard deviation. \n",
        "####mean = [0.7203, 0.5801, 0.8061]\n",
        "####std = [0.1581, 0.1728, 0.1076]\n"
      ],
      "metadata": {
        "id": "8iiYWeMB1vS0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvhA5NvN97k7"
      },
      "outputs": [],
      "source": [
        "#mean, std = mean_and_std(train_loader)\n",
        "#print(mean)\n",
        "#print(std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXA7K3ZKD2H8"
      },
      "outputs": [],
      "source": [
        "mean = torch.Tensor([0.7203, 0.5801, 0.8061])\n",
        "std = torch.Tensor([0.1581, 0.1728, 0.1076])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The dataset is loaded from the train folder and following transformations are performed - \n",
        "####1. transforms.Resize - Resizing the images from input size to 128x128\n",
        "####2. transforms.RandomHorizontalFlip - Random flipping of the images so that the train data is more variable and better trains the model.\n",
        "####3. transforms.RandomRotation(10) - Randomly rotating train images by 10 degress, again to introduce more variability to the train data\n",
        "####4. transforms.ToTensor - All the values are changed to a Tensor that is necessary as all functionalities Pytorch work on tensors.\n",
        "####5. transforms.Normalize(mean, std) - Normalization of the train data based on the calculated mean and standard deviation"
      ],
      "metadata": {
        "id": "hpf7YKL3TSw9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSDy9Aaq004k"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms.transforms import RandomHorizontalFlip, RandomRotation\n",
        "train_dataset = dset.ImageFolder(root=train_dir,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.RandomHorizontalFlip(),\n",
        "                               transforms.RandomRotation(10),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize(mean, std),\n",
        "                           ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXiODe3gkWFT",
        "outputId": "94abde91-905d-4f97-8ffd-f508d12bca05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1700"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ],
      "source": [
        "len(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The train data in the train folder is further divided into training set and validation set. The split is approximately 75% and 25% data respectively."
      ],
      "metadata": {
        "id": "uLb92CCHUhMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, val_set = torch.utils.data.random_split(train_dataset, [1250, 450])"
      ],
      "metadata": {
        "id": "1txT6MJoc9fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The convulutional model is defined below having 8 layers -\n",
        "####Input shape [batch_size, no. of channels, widht and height of image, thus [128, 3, 128, 128]\n",
        "####1. ConV layer - input channels = 3 (As RGB for coloured images) output channels = 12, Batch normalization and activation function as RelU\n",
        "####Output shape = [128, 12, 128, 128]\n",
        "####2. Max Pooling layer - of kernel size 2 \n",
        "####Output shape = [128, 12, 64, 64]\n",
        "####3. ConV layer - input channels = 12 (As RGB for coloured images) output channels = 20, Batch normalization and activation function as RelU\n",
        "####Output shape = [128, 20, 64, 64]\n",
        "####4. Max Pooling layer - of kernel size 2 \n",
        "####Output shape = [128, 12, 32, 32]\n",
        "####5. ConV layer - input channels = 20 (As RGB for coloured images) output channels = 32, Batch normalization and activation function as RelU\n",
        "####Output shape = [128, 32, 32, 32]\n",
        "####6. ConV layer - input channels = 32 (As RGB for coloured images) output channels = 64, Batch normalization and activation function as RelU\n",
        "####Output shape = [128, 64, 32, 32]\n",
        "####7. Fully connected layer - in features = 64 * 32 * 32, out features = 1028\n",
        "####8. Fully connected layer - in features = 1028, out features = 4 (no. of class labels)"
      ],
      "metadata": {
        "id": "crcf03QlU7ka"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sILmYwf1PYN"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "model = nn.Sequential(collections.OrderedDict([\n",
        "          ('conv1', nn.Conv2d(3,12,3,padding=1)),\n",
        "          ('bn1',   nn.BatchNorm2d(num_features=12)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('mp1',   nn.MaxPool2d(2)),\n",
        "\n",
        "          ('conv2', nn.Conv2d(12,20,3,padding=1)),\n",
        "          ('relu2', nn.ReLU()),\n",
        "          ('mp2',   nn.MaxPool2d(2)),\n",
        "\n",
        "          ('conv3', nn.Conv2d(20,32,3,padding=1)),\n",
        "          ('relu3', nn.ReLU()),\n",
        "\n",
        "          ('conv4', nn.Conv2d(32,64,3,padding=1)),\n",
        "          ('bn3',   nn.BatchNorm2d(num_features=64)),\n",
        "          ('relu4', nn.ReLU()),\n",
        "          \n",
        "          \n",
        "          # Put in a linear layers ...\n",
        "          ('flatten', nn.Flatten()),                                          \n",
        "          ('fc1', nn.Linear(64*32*32,1028)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('fc2', nn.Linear(1028,4)),\n",
        "        ]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Functions training_loop and validatio_loop are defined below for training and validation of our ConVnet model defined above.\n",
        "####The model is set to train mode in training loop and eval mode in validation loop.\n",
        "####For every epoch we load train/validation data in batches. \n",
        "####While training, the outputs from the model is calculated, which are in turn passed in a loss function. \n",
        "####The optimizier is reset to zero gradient for every epoch. And based on the learning rate and the loss gradient a step is taken by the optimizer.\n",
        "####The predictions are made and cross checked with actual labels for calculating the correct predicted labels. This in turn helps in calculating the training accuracy of the model in the current epoch.\n",
        "####In every epoch the model in its current state is also used to make predictions on the validation set using validation loop function (logic similar to training loop) and accuracy on the validation set is used to keep a check of best accuracy.\n",
        "####The model state having the best validation set accuracy is saved as the model with best settings.  "
      ],
      "metadata": {
        "id": "iC9uERXrYQOS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3iRvBNk5dR5"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "epoch_print_gap = 1\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, device, loss_fn, train_loader, validation_loader):\n",
        "    model.train()\n",
        "    model = model.to(device)\n",
        "    best_acc = 0\n",
        "    val_acc = 0.0\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        print('Epoch: ', epoch)\n",
        "        loss_train = 0.0\n",
        "        correct = 0\n",
        "        for imgs, labels in train_loader:\n",
        "            outputs = model(imgs.to(device))\n",
        "            loss = loss_fn(outputs, labels.to(device))\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            loss_train += loss.item()\n",
        "\n",
        "            pred = outputs.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "\n",
        "        loss_train /= len(train_loader.dataset)\n",
        "        curr_acc = 100. * correct / len(train_loader.dataset)\n",
        "\n",
        "        val_acc = validation_loop(model, device, validation_loader)\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "          model_save_name = 'best_model.pt'\n",
        "          path = F\"/content/gdrive/MyDrive/Colab Notebooks/{model_save_name}\" \n",
        "          torch.save(model.state_dict(), path)\n",
        "          print('model saved')\n",
        "          best_acc = val_acc\n",
        "\n",
        "        if epoch == 1 or epoch % epoch_print_gap == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch, float(loss_train)))\n",
        "            print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "                loss_train, correct, len(train_loader.dataset),  curr_acc))\n",
        "            \n",
        "            print('Validation set: Accuracy: ({:.0f}%)\\n'.format(val_acc))\n",
        "            \n",
        "\n",
        "def validation_loop(model, device, validation_loader):\n",
        "  model.eval()\n",
        "  model = model.to(device)\n",
        "\n",
        "  correct = 0\n",
        "  val_acc = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data, labels in validation_loader:\n",
        "      output = model(data.to(device))\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      pred = output.argmax(dim=1, keepdim=True)\n",
        "      correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "  \n",
        "  val_acc = 100. * correct / len(validation_loader.dataset)\n",
        "  return val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZgcsefcHZcx"
      },
      "outputs": [],
      "source": [
        "#learning rate\n",
        "lr = 0.005\n",
        "\n",
        "# set up a train and a validation loader objects to use minibatches of 128 images in a batch with shuffle True\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 128, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(val_set, batch_size = 128, shuffle=True)\n",
        "\n",
        "# we set the optimiser as Stochastic Gradient Descent\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###To handle the imbalance in the classes in training data the weights parameter of the loss function is used. \n",
        "####Classes Cancer, Connective and Immune have 500 images each while Normal class has only 200 images.\n",
        "####Thus weights are calculated as follows\n",
        "###sum of all classes/sum of images in each class -\n",
        "###For Cancer,  Connective and Immune 1700/500 = 3.4\n",
        "###For Normal 1700/200 = 8.5"
      ],
      "metadata": {
        "id": "gYDKZnRNbc8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.tensor([3.4, 3.4, 3.4, 8.5])\n",
        "weights = weights.to(device)\n",
        "\n",
        "# we set the loss function to optimise. Cross Entropy is usually the best for \n",
        "# classification\n",
        "loss_fn = nn.CrossEntropyLoss(weight=weights )"
      ],
      "metadata": {
        "id": "KTsNJ9F4bbyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###With 20 epochs the ConVnet is trained"
      ],
      "metadata": {
        "id": "vIQhHTBscX9F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9FXssucHcxS",
        "outputId": "db4fa629-8b6e-4759-d9a8-ae1a4147b1e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1\n",
            "model saved\n",
            "2022-03-25 14:27:05.641366 Epoch 1, Training loss 0.011520847606658936\n",
            "\n",
            "Train set: Average loss: 0.0115, Accuracy: 538/1250 (43%)\n",
            "\n",
            "\\Validation set: Accuracy:(80%)\n",
            "\n",
            "Epoch:  2\n",
            "2022-03-25 14:27:35.431325 Epoch 2, Training loss 0.009432905387878419\n",
            "\n",
            "Train set: Average loss: 0.0094, Accuracy: 979/1250 (78%)\n",
            "\n",
            "\\Validation set: Accuracy:(80%)\n",
            "\n",
            "Epoch:  3\n",
            "model saved\n",
            "2022-03-25 14:28:09.447467 Epoch 3, Training loss 0.008464416694641113\n",
            "\n",
            "Train set: Average loss: 0.0085, Accuracy: 981/1250 (78%)\n",
            "\n",
            "\\Validation set: Accuracy:(84%)\n",
            "\n",
            "Epoch:  4\n",
            "model saved\n",
            "2022-03-25 14:28:40.485148 Epoch 4, Training loss 0.007263839340209961\n",
            "\n",
            "Train set: Average loss: 0.0073, Accuracy: 1019/1250 (82%)\n",
            "\n",
            "\\Validation set: Accuracy:(86%)\n",
            "\n",
            "Epoch:  5\n",
            "model saved\n",
            "2022-03-25 14:29:09.699663 Epoch 5, Training loss 0.005929233837127686\n",
            "\n",
            "Train set: Average loss: 0.0059, Accuracy: 1049/1250 (84%)\n",
            "\n",
            "\\Validation set: Accuracy:(86%)\n",
            "\n",
            "Epoch:  6\n",
            "2022-03-25 14:29:36.900996 Epoch 6, Training loss 0.005051283740997315\n",
            "\n",
            "Train set: Average loss: 0.0051, Accuracy: 1043/1250 (83%)\n",
            "\n",
            "\\Validation set: Accuracy:(86%)\n",
            "\n",
            "Epoch:  7\n",
            "2022-03-25 14:30:03.549089 Epoch 7, Training loss 0.004673281097412109\n",
            "\n",
            "Train set: Average loss: 0.0047, Accuracy: 1025/1250 (82%)\n",
            "\n",
            "\\Validation set: Accuracy:(86%)\n",
            "\n",
            "Epoch:  8\n",
            "2022-03-25 14:30:30.173235 Epoch 8, Training loss 0.004369095993041992\n",
            "\n",
            "Train set: Average loss: 0.0044, Accuracy: 1028/1250 (82%)\n",
            "\n",
            "\\Validation set: Accuracy:(85%)\n",
            "\n",
            "Epoch:  9\n",
            "2022-03-25 14:30:57.451445 Epoch 9, Training loss 0.004311432957649231\n",
            "\n",
            "Train set: Average loss: 0.0043, Accuracy: 1030/1250 (82%)\n",
            "\n",
            "\\Validation set: Accuracy:(85%)\n",
            "\n",
            "Epoch:  10\n",
            "2022-03-25 14:31:23.525715 Epoch 10, Training loss 0.004133306312561035\n",
            "\n",
            "Train set: Average loss: 0.0041, Accuracy: 1047/1250 (84%)\n",
            "\n",
            "\\Validation set: Accuracy:(85%)\n",
            "\n",
            "Epoch:  11\n",
            "2022-03-25 14:31:49.963943 Epoch 11, Training loss 0.003986198329925537\n",
            "\n",
            "Train set: Average loss: 0.0040, Accuracy: 1051/1250 (84%)\n",
            "\n",
            "\\Validation set: Accuracy:(85%)\n",
            "\n",
            "Epoch:  12\n",
            "2022-03-25 14:32:16.347984 Epoch 12, Training loss 0.0039673485279083254\n",
            "\n",
            "Train set: Average loss: 0.0040, Accuracy: 1055/1250 (84%)\n",
            "\n",
            "\\Validation set: Accuracy:(86%)\n",
            "\n",
            "Epoch:  13\n",
            "2022-03-25 14:32:43.090521 Epoch 13, Training loss 0.003737324619293213\n",
            "\n",
            "Train set: Average loss: 0.0037, Accuracy: 1066/1250 (85%)\n",
            "\n",
            "\\Validation set: Accuracy:(86%)\n",
            "\n",
            "Epoch:  14\n",
            "model saved\n",
            "2022-03-25 14:33:10.849472 Epoch 14, Training loss 0.0038083595514297485\n",
            "\n",
            "Train set: Average loss: 0.0038, Accuracy: 1052/1250 (84%)\n",
            "\n",
            "\\Validation set: Accuracy:(87%)\n",
            "\n",
            "Epoch:  15\n",
            "model saved\n",
            "2022-03-25 14:33:37.547795 Epoch 15, Training loss 0.003616100835800171\n",
            "\n",
            "Train set: Average loss: 0.0036, Accuracy: 1063/1250 (85%)\n",
            "\n",
            "\\Validation set: Accuracy:(87%)\n",
            "\n",
            "Epoch:  16\n",
            "2022-03-25 14:34:03.908720 Epoch 16, Training loss 0.0034526416301727293\n",
            "\n",
            "Train set: Average loss: 0.0035, Accuracy: 1079/1250 (86%)\n",
            "\n",
            "\\Validation set: Accuracy:(80%)\n",
            "\n",
            "Epoch:  17\n",
            "model saved\n",
            "2022-03-25 14:34:31.513052 Epoch 17, Training loss 0.003587339901924133\n",
            "\n",
            "Train set: Average loss: 0.0036, Accuracy: 1059/1250 (85%)\n",
            "\n",
            "\\Validation set: Accuracy:(88%)\n",
            "\n",
            "Epoch:  18\n",
            "2022-03-25 14:34:57.708133 Epoch 18, Training loss 0.003654545474052429\n",
            "\n",
            "Train set: Average loss: 0.0037, Accuracy: 1071/1250 (86%)\n",
            "\n",
            "\\Validation set: Accuracy:(76%)\n",
            "\n",
            "Epoch:  19\n",
            "2022-03-25 14:35:24.204061 Epoch 19, Training loss 0.0037946154356002806\n",
            "\n",
            "Train set: Average loss: 0.0038, Accuracy: 1063/1250 (85%)\n",
            "\n",
            "\\Validation set: Accuracy:(83%)\n",
            "\n",
            "Epoch:  20\n",
            "2022-03-25 14:35:50.669070 Epoch 20, Training loss 0.0034584001779556276\n",
            "\n",
            "Train set: Average loss: 0.0035, Accuracy: 1070/1250 (86%)\n",
            "\n",
            "\\Validation set: Accuracy:(86%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 20 \n",
        "\n",
        "\n",
        "# train the CNN\n",
        "training_loop(\n",
        "    n_epochs = n_epochs, \n",
        "    optimizer = optimizer,\n",
        "    model = model, \n",
        "    device = device,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        "    validation_loader = validation_loader,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The model with best settings which was saved in loaded for making predictions on the test data and submit predictions to Kaggle."
      ],
      "metadata": {
        "id": "ikQChH6Ccec3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDuX0MoQsaGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f1fe1d-cd53-46cd-b756-f74bf7ea966a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ],
      "source": [
        "model_save_name = 'best_model.pt'\n",
        "path = F\"/content/gdrive/MyDrive/Colab Notebooks/{model_save_name}\" \n",
        "model.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We set up a loader for test data, using a single batch - \n",
        "\n",
        "#### Transformations are similar to train data excpet transforms.RandomHorizontalFlip transforms.RandomRotation\n",
        "\n"
      ],
      "metadata": {
        "id": "Pta1HKS6eXT7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgzdTixMFxqx"
      },
      "outputs": [],
      "source": [
        "test_dataset = dset.ImageFolder(root=test_dir,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.CenterCrop(image_size),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize(mean, std),\n",
        "                           ]))\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "co2YJbY_FzDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8475adb6-170a-4cd4-b26e-29952a883844"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 3200\n",
              "    Root location: /content/gdrive/MyDrive/Colab Notebooks/data/test\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=128, interpolation=bilinear, max_size=None, antialias=None)\n",
              "               CenterCrop(size=(128, 128))\n",
              "               ToTensor()\n",
              "               Normalize(mean=tensor([0.7203, 0.5801, 0.8061]), std=tensor([0.1581, 0.1728, 0.1076]))\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ],
      "source": [
        "test_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###To make the predictions on the test data we utilize our model with best settings and store the predictions as a csv file.  "
      ],
      "metadata": {
        "id": "Gt1BHmNKe7aQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEnPgkIkHNVH"
      },
      "outputs": [],
      "source": [
        "pred =[]\n",
        "model.eval()\n",
        "for data, target in test_loader:\n",
        "  \n",
        "  output = model(data.to(device))\n",
        "  pred.append(output.argmax(dim=1, keepdim=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The predictions are changed to their respective class label strings and stored in a dictionary"
      ],
      "metadata": {
        "id": "jFsMUXhBhI0z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRFSGGmlHjYX"
      },
      "outputs": [],
      "source": [
        "preds = {}\n",
        "for i in range(len(pred)):\n",
        "  preds[test_dataset.imgs[i][0].split('/')[-1]]=classes[pred[i]]\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dictionary is converted to a csv file."
      ],
      "metadata": {
        "id": "pOMMU7-0hIIh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGyBg4vUd_HU"
      },
      "outputs": [],
      "source": [
        "with open('/content/gdrive/My Drive/Colab Notebooks/predictions.csv', 'w') as f:\n",
        "    f.write(\"%s,%s\\n\"%('Id','Type'))\n",
        "    for key in preds.keys():\n",
        "        f.write(\"%s,%s\\n\"%(key,preds[key]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Bison.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}